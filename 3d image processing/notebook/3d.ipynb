{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pydicom import dcmread\n",
    "from pydicom.data import get_testdata_file\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/shihab/Desktop/Machine Learning/Dataset/3dImageDataset/minData/147-Tahera Sultana. Dr_Nurul_Amin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the combined data: (1350, 360000)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# Directory containing patient folders\n",
    "base_dir = \"/home/shihab/Desktop/Machine Learning/Dataset/3dImageDataset/minData\"\n",
    "\n",
    "# List to store all pixel data\n",
    "all_patient_data = []\n",
    "\n",
    "# Iterate through patient folders\n",
    "patients = os.listdir(base_dir)\n",
    "for patient in patients:\n",
    "    patient_dir = os.path.join(base_dir, patient)\n",
    "    dicom_files = [f for f in os.listdir(patient_dir) if f.endswith('.dcm')]\n",
    "\n",
    "    for dicom_file in dicom_files:\n",
    "        file_path = os.path.join(patient_dir, dicom_file)\n",
    "        \n",
    "        # Read DICOM file\n",
    "        dicom_data = pydicom.dcmread(file_path)\n",
    "        \n",
    "        # Extract pixel array and normalize it\n",
    "        pixel_array = dicom_data.pixel_array\n",
    "        normalized_pixels = (pixel_array - np.min(pixel_array)) / (np.max(pixel_array) - np.min(pixel_array))\n",
    "        \n",
    "        # Flatten the array and append to the list\n",
    "        all_patient_data.append(pixel_array.flatten())\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "dt = np.array(all_patient_data)\n",
    "\n",
    "# Print the shape of the resulting array\n",
    "print(\"Shape of the combined data:\", dt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_dicom_series(base_dir):\n",
    "    slices = []\n",
    "    for filename in sorted(os.listdir(base_dir)):\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            filepath = os.path.join(base_dir, filename)\n",
    "            slices.append(pydicom.dcmread(filepath))\n",
    "    slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))  # Sort by slice position\n",
    "    volume = np.stack([s.pixel_array for s in slices], axis=-1)  # Create 3D volume\n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(volume):\n",
    "    volume = volume - np.min(volume)\n",
    "    volume = volume / np.max(volume)\n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "def resample_volume(volume, new_spacing=(1.0, 1.0, 1.0)):\n",
    "    sitk_volume = sitk.GetImageFromArray(volume)\n",
    "    original_spacing = sitk_volume.GetSpacing()\n",
    "    original_size = sitk_volume.GetSize()\n",
    "    new_size = [\n",
    "        int(np.round(original_size[i] * (original_spacing[i] / new_spacing[i])))\n",
    "        for i in range(3)\n",
    "    ]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetSize(new_size)\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    resampled_volume = resampler.Execute(sitk_volume)\n",
    "    return sitk.GetArrayFromImage(resampled_volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_slices(volume):\n",
    "    return [volume[:, :, i] for i in range(volume.shape[2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/shihab/.local/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: pydicom in /home/shihab/.local/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: opencv-python in /home/shihab/.local/lib/python3.10/site-packages (4.10.0.84)\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m57.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/shihab/.local/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: SimpleITK in /home/shihab/.local/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: nibabel in /home/shihab/.local/lib/python3.10/site-packages (5.3.2)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/615.3 MB\u001b[0m \u001b[31m23.2 kB/s\u001b[0m eta \u001b[36m4:46:54\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 466, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1303, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1159, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/cli/base_command.py\", line 165, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/cli/req_command.py\", line 205, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/commands/install.py\", line 339, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 348, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 215, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 288, in __init__\n",
      "    super().__init__(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 299, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 487, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 532, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 214, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 94, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/network/download.py\", line 146, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/cli/progress_bars.py\", line 304, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 512, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install numpy pydicom opencv-python scikit-image matplotlib SimpleITK nibabel tensorflow keras pytorch torchvision monai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munet_model\u001b[39m(input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m1\u001b[39m)):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "!pip install numpy pydicom opencv-python scikit-image matplotlib SimpleITK nibabel tensorflow keras pytorch torchvision monai\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "\n",
    "def unet_model(input_size=(128, 128, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    # Add more layers similarly...\n",
    "    up = UpSampling2D((2, 2))(p1)\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(up)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
